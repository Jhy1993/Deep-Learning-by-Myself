# -*- coding: utf-8 -*-"""Created on Fri Mar 24 09:25:58 2017@author: samsung基于cnn的IBM预测"""import osimport timeimport json import h5py import numpy as npfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Dropout,Activationfrom keras.layers.normalization import BatchNormalizationfrom keras.callbacks import ModelCheckpointfrom keras.models import model_from_json import scipy.io as sciodef get_data(dirpath):    data_list = []    for file in os.listdir(dirpath):        filepath = os.path.join(dirpath, file)        if os.path.isfile(filepath):            data_list.append(filepath)    return data_listdef data_generator(dirpath):    data_list = get_data(dirpath)    batch_size = 32    while True:        x = []        y = []        for i in range(batch_size):            cnt = np.random.choice(len(data_list))            data = scio.loadmat(data_list[cnt])            yt = data['IBM']            xt = data['yo']            x.append(xt)             y.append(yt)        y = np.array(y).astype('float32')        x = np.array(x).astype('float32') / np.max(x) #归一化值        x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)        yy = y.reshape(y.shape[0], y.shape[1])        yield (x, yy)def CNN_model(image_shape=(28, 28, 1), nb_classes=10):    # 多个3*3卷积 之后 一个池化    print('model input shape:{}, model output shape: {}'.format(image_shape, nb_classes))    model = Sequential()    # conv 1    model.add(Convolution2D(32, 3, 3, border_mode='same',                            input_shape=image_shape))    # 32是卷积核数 3，3是卷积核大小#    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))    model.add(Dropout(0.5))        # conv 2    model.add(Convolution2D(64, 3, 3, border_mode='same'))#    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))    model.add(Dropout(0.5))        # conv 3    model.add(Convolution2D(64, 3, 3, border_mode='same'))    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))    model.add(Dropout(0.5))#    model.add(BatchNormalization(axis=3))#==========================这里卷积层数按需要调整==============================       # dense 1    model.add(Flatten())    # 矩阵压平成列向量    model.add(Dense(512))    model.add(Dropout(0.5))        # dese 2    model.add(Dense(nb_classes))    model.add(Activation('softmax'))        model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])    print('=======================Model Architecture============================')    model.summary()    return model# train_data [None, row, col, channel]# train_label [None, label]def train(model, train_data, train_label,          test_data, test_label,          save_dir='./SaveModels',          model_name='model.json',          weight_name='model.h5'):    if not os.path.exists(save_dir):        os.mkdir(save_dir)    print('Start train model:')    model.fit(train_data, train_label, batch_size=32, nb_epoch=50,                    verbose=2)    score, acc = model.evaluate(test_data, test_label, batch_size=32)    print('test accuracy: {}'.format(acc))    json_string = model.to_json()    save_model = os.path.join(save_dir, model_name)    save_weight = os.path.join(save_dir, weight_name)    fd = open(save_model, 'w')    fd.write(json_string)    fd.close()    model.save_weights(save_weight)    print('model saved')    return modeldef train_on_generator(model, generator,#          test_data, test_label,          save_dir='./SaveModels',          model_name='model.json',          weight_name='model.h5'):    if not os.path.exists(save_dir):        os.mkdir(save_dir)    print('Start train model on generator:')    model.fit_generator(generator, samples_per_epoch=3200, nb_epoch=2)#    score, acc = model.evaluate(test_data, test_label, batch_size=32)#    print('test accuracy: {}'.format(acc))    json_string = model.to_json()    save_model = os.path.join(save_dir, model_name)    save_weight = os.path.join(save_dir, weight_name)    fd = open(save_model, 'w')    fd.write(json_string)    fd.close()    model.save_weights(save_weight)    print('model saved')    return model    def load_model(save_dir, model_name, weight_name):    model = model_from_json(open(os.path.join(save_dir, model_name).read()))    model.load_weights(os.path.join(save_dir, weight_name))    return model    #===========================================运行============================# 读取 生成 数据    dirpath = 'C:\\Users\\samsung\\Desktop\\IBM_FFT'      generator= data_generator(dirpath)# 设置 语谱图大小 与 label大小image_shape = (257, 8, 1)nb_classes = 257# 建立 模型model = CNN_model(image_shape, nb_classes)# 训练模型并保存save_dir='./SaveModels'model_name = 'model_0324.json'weight_name = 'weight_0324.h5'train_on_generator(model, generator, save_dir, model_name, weight_name)# 读取模型 预测#model = load_model(save_dir, model_name, weight_name)# re = model.pred_prob()
